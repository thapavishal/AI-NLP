{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_textClassificationMultiGroup-02.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWT1M_d_6Ln-"
      },
      "source": [
        "import numpy as np\r\n",
        "from keras.layers import Activation,Dense,Dropout\r\n",
        "from keras.models import Sequential\r\n",
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "from sklearn import datasets as skds\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "import pickle\r\n",
        "from keras.models import load_model\r\n",
        "from pathlib import Path\r\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSLWIxwZktvG"
      },
      "source": [
        "path_data = \"/content/drive/MyDrive/text classification/bbc\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z52ijw6k0R1"
      },
      "source": [
        "files = skds.load_files(path_data,load_content= False)\r\n",
        "label_index = files.target\r\n",
        "label_names = files.target_names\r\n",
        "labelled_files = files.filenames\r\n",
        "\r\n",
        "data_tags = [\"filename\",\"category\",\"news\"]\r\n",
        "i = 0\r\n",
        "data_list = []\r\n",
        "for file in labelled_files:\r\n",
        "  data_list.append((file, label_names[label_index[i]],Path(file).read_text()))\r\n",
        "  i = i+1\r\n",
        "\r\n",
        "data = pd.DataFrame.from_records(data_list,columns = data_tags)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQVMZL-Xntfg"
      },
      "source": [
        "'''\r\n",
        "for notebook::\r\n",
        "data_tags = [\"filename\",\"category\",\"news\"]\r\n",
        "i = 0\r\n",
        "data_list = []\r\n",
        "for f in labelled_files:\r\n",
        "  data_list.append(f,label_name[label_index[i]])\r\n",
        "  b = open(f,'r')\r\n",
        "  c = b.read()\r\n",
        "  print(c)\r\n",
        "  data_list.append((c,))\r\n",
        "  data_list.append(f,label_names[label_index[i]])\r\n",
        "  i = i+1\r\n",
        "\r\n",
        "print(data_list)\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "XSojSLJVrXom",
        "outputId": "b9896a37-1951-4ef2-c8ff-7e573e43bbbf"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>category</th>\n",
              "      <th>news</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/text classification/bbc...</td>\n",
              "      <td>tech</td>\n",
              "      <td>Net regulation 'still possible'\\n\\nThe blurrin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/text classification/bbc...</td>\n",
              "      <td>business</td>\n",
              "      <td>VW considers opening Indian plant\\n\\nVolkswage...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/text classification/bbc...</td>\n",
              "      <td>business</td>\n",
              "      <td>Court rejects $280bn tobacco case\\n\\nA US gove...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/text classification/bbc...</td>\n",
              "      <td>business</td>\n",
              "      <td>AstraZeneca hit by drug failure\\n\\nShares in A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/text classification/bbc...</td>\n",
              "      <td>business</td>\n",
              "      <td>J&amp;J agrees $25bn Guidant deal\\n\\nPharmaceutica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>/content/drive/MyDrive/text classification/bbc...</td>\n",
              "      <td>politics</td>\n",
              "      <td>Labour chooses Manchester\\n\\nThe Labour Party ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1516</th>\n",
              "      <td>/content/drive/MyDrive/text classification/bbc...</td>\n",
              "      <td>politics</td>\n",
              "      <td>Report attacks defence spending\\n\\nThe Ministr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1517</th>\n",
              "      <td>/content/drive/MyDrive/text classification/bbc...</td>\n",
              "      <td>tech</td>\n",
              "      <td>Rich pickings for hi-tech thieves\\n\\nViruses, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1518</th>\n",
              "      <td>/content/drive/MyDrive/text classification/bbc...</td>\n",
              "      <td>entertainment</td>\n",
              "      <td>McCririck out of Big Brother show\\n\\nRacing pu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1519</th>\n",
              "      <td>/content/drive/MyDrive/text classification/bbc...</td>\n",
              "      <td>entertainment</td>\n",
              "      <td>The comic book genius of Stan Lee\\n\\nStan Lee,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1520 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               filename  ...                                               news\n",
              "0     /content/drive/MyDrive/text classification/bbc...  ...  Net regulation 'still possible'\\n\\nThe blurrin...\n",
              "1     /content/drive/MyDrive/text classification/bbc...  ...  VW considers opening Indian plant\\n\\nVolkswage...\n",
              "2     /content/drive/MyDrive/text classification/bbc...  ...  Court rejects $280bn tobacco case\\n\\nA US gove...\n",
              "3     /content/drive/MyDrive/text classification/bbc...  ...  AstraZeneca hit by drug failure\\n\\nShares in A...\n",
              "4     /content/drive/MyDrive/text classification/bbc...  ...  J&J agrees $25bn Guidant deal\\n\\nPharmaceutica...\n",
              "...                                                 ...  ...                                                ...\n",
              "1515  /content/drive/MyDrive/text classification/bbc...  ...  Labour chooses Manchester\\n\\nThe Labour Party ...\n",
              "1516  /content/drive/MyDrive/text classification/bbc...  ...  Report attacks defence spending\\n\\nThe Ministr...\n",
              "1517  /content/drive/MyDrive/text classification/bbc...  ...  Rich pickings for hi-tech thieves\\n\\nViruses, ...\n",
              "1518  /content/drive/MyDrive/text classification/bbc...  ...  McCririck out of Big Brother show\\n\\nRacing pu...\n",
              "1519  /content/drive/MyDrive/text classification/bbc...  ...  The comic book genius of Stan Lee\\n\\nStan Lee,...\n",
              "\n",
              "[1520 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-ZKehbLreLC",
        "outputId": "dbe628c9-18ae-403f-f22d-8082ab8f47c7"
      },
      "source": [
        "df = data\r\n",
        "data_len = len(df)\r\n",
        "train_data = int(data_len*0.8)\r\n",
        "data_len"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1520"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHKGy44Ks6IR"
      },
      "source": [
        "train_tag = df['category'][:train_data]\r\n",
        "train_post = df['news'][:train_data]  # tokanize garnu agadi ko x_train ho yo\r\n",
        "\r\n",
        "test_tag = df['category'][train_data:]\r\n",
        "test_post = df['news'][train_data:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGxQJ5mktelx"
      },
      "source": [
        "import numpy as np\r\n",
        "from keras.layers import Activation, Dense, Dropout\r\n",
        "from keras.models import Sequential\r\n",
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIW00sehtzEf"
      },
      "source": [
        "num_labels = 4       # categories haru mathi herera\r\n",
        "vocab_size = 1500    # (1 sec)ekchoti ma kati ota text data lai vector ko format ma pathauney\r\n",
        "                     # news ma kati words cha tesma depend garcha \r\n",
        "                     # i.e 0 ma tech category ma kati words cha tah\r\n",
        "### vocab_size ---> euta category ko news ma number of words kati cha bhanne?\r\n",
        "batch_size = 100\r\n",
        "# mathi ko data haru guess garera rakhne ho pachi tuning garera milauna sakincha\r\n",
        "\r\n",
        "\r\n",
        "### define Tokenizer with vocab size  ###\r\n",
        "# kun word chai kun class sanga related cha bhanne\r\n",
        "# i.e bank ma jada line milauna token diyeko jasto\r\n",
        "# NN ley queue lai manage garna token use garcha\r\n",
        "\r\n",
        "tokenizer = Tokenizer(num_words = vocab_size)\r\n",
        "tokenizer.fit_on_texts(train_post) # tokanize chai content(text) lai garne\r\n",
        "\r\n",
        "# tokanize chai post(content) lai garne\r\n",
        "x_train = tokenizer.texts_to_matrix(train_post,mode='tfidf')\r\n",
        "x_test = tokenizer.texts_to_matrix(test_post,mode ='tfidf')\r\n",
        "\r\n",
        "encoder = LabelBinarizer() # CNN ma sequential layer use gareko jasto \r\n",
        "encoder.fit(train_tag)  # encode chai tag(i.e category hamro mathi ko case ma) lai garne\r\n",
        "\r\n",
        "# encode chai tag (i.e category ) lai garne\r\n",
        "y_train = encoder.transform(train_tag)\r\n",
        "y_test = encoder.transform(test_tag) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNyJLSbKuqko",
        "outputId": "8bf4e682-3abc-4ab9-e80a-8e4afbb2cc5f"
      },
      "source": [
        "# NN ko kaam start bhayo aba\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(512,input_shape = (vocab_size,)))\r\n",
        "model.add(Activation('relu'))\r\n",
        "model.add(Dropout(0.3))\r\n",
        "\r\n",
        "model.add(Dense(256))\r\n",
        "model.add(Activation('relu'))\r\n",
        "model.add(Dropout(0.3))\r\n",
        "\r\n",
        "model.add(Dense(num_labels))\r\n",
        "model.add(Activation('softmax'))\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               768512    \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 1028      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 4)                 0         \n",
            "=================================================================\n",
            "Total params: 900,868\n",
            "Trainable params: 900,868\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlxHlGxoutg6"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy',\r\n",
        "             optimizer = 'adam',\r\n",
        "             metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt-QoItauwLh",
        "outputId": "e86d3e46-00e0-4ab4-ea15-a8f0b142e5fe"
      },
      "source": [
        "history = model.fit(x_train,y_train,epochs = 10,validation_split = 0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "35/35 [==============================] - 1s 14ms/step - loss: 0.8885 - accuracy: 0.6576 - val_loss: 0.1522 - val_accuracy: 0.9508\n",
            "Epoch 2/10\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0810 - accuracy: 0.9679 - val_loss: 0.0966 - val_accuracy: 0.9672\n",
            "Epoch 3/10\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0107 - accuracy: 0.9977 - val_loss: 0.0671 - val_accuracy: 0.9754\n",
            "Epoch 4/10\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 0.9978 - val_loss: 0.0935 - val_accuracy: 0.9672\n",
            "Epoch 5/10\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0102 - accuracy: 0.9986 - val_loss: 0.0736 - val_accuracy: 0.9836\n",
            "Epoch 6/10\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0669 - val_accuracy: 0.9754\n",
            "Epoch 7/10\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.0674 - val_accuracy: 0.9754\n",
            "Epoch 8/10\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9836\n",
            "Epoch 9/10\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0660 - val_accuracy: 0.9672\n",
            "Epoch 10/10\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmFOotMGuy6l"
      },
      "source": [
        "# saving the model\r\n",
        "\r\n",
        "import pickle\r\n",
        "model.save('/content/drive/MyDrive/text classification/bbc2.h5')\r\n",
        "with open('tokenizer.pickle','wb') as f:\r\n",
        "  pickle.dump(tokenizer,f,protocol = pickle.HIGHEST_PROTOCOL)\r\n",
        "# pickle chai serialization ko lagi chahincha"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKg3fbVkwIH3"
      },
      "source": [
        "# loading the model\r\n",
        "from keras.models import load_model\r\n",
        "model = load_model('/content/drive/MyDrive/text classification/bbc2.h5')\r\n",
        "\r\n",
        "# tokenizer = Tokenizer()\r\n",
        "# aba read mode ma kholne\r\n",
        "# model testing ko lagi\r\n",
        "with open('tokenizer.pickle','rb') as f:\r\n",
        "  tokenizers = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2B3zwiTwQtf",
        "outputId": "40f42c46-fc50-4372-b0f7-283fbc57d8c7"
      },
      "source": [
        "encoder.classes_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['business', 'entertainment', 'politics', 'tech'], dtype='<U13')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFpDM4xXwVam"
      },
      "source": [
        "labels = np.array(['business', 'entertainment', 'politics', 'tech'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mknqe4UYwYbW"
      },
      "source": [
        "b = open('news2.txt','w')\r\n",
        "b.write(\"A mobile phone has become more than just a medium to call somebody. It has become something more. Its multiple uses have made it a necessity for most of us, especially for those who use social media. And, if you are on any social media platform, you are bound to post stuff on it, including pictures.\")\r\n",
        "b.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3OvEjxLzguZ",
        "outputId": "8dea6ee2-fa8a-42f3-c81a-0def36b5efe4"
      },
      "source": [
        "b = open('news2.txt','r')\r\n",
        "print(b.read())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A mobile phone has become more than just a medium to call somebody. It has become something more. Its multiple uses have made it a necessity for most of us, especially for those who use social media. And, if you are on any social media platform, you are bound to post stuff on it, including pictures.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLxMPNIYzudh"
      },
      "source": [
        "test_files = ['news2.txt']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQsD6kASwazN"
      },
      "source": [
        "from pathlib import Path\r\n",
        "import pandas as pd\r\n",
        "x_data = []\r\n",
        "for t_f in test_files:\r\n",
        "  t_f_data = Path(t_f).read_text()\r\n",
        "  x_data.append(t_f_data)\r\n",
        "\r\n",
        "x_data_series = pd.Series(x_data)\r\n",
        "x_tokenized = tokenizer.texts_to_matrix(x_data_series, mode = 'tfidf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJt9kGpFwfTy",
        "outputId": "80c46292-b23d-47c9-8ec6-81339316471f"
      },
      "source": [
        "# for prediction\r\n",
        "for x_t in x_tokenized:\r\n",
        "  prediction = model.predict(np.array([x_t]))\r\n",
        "  print(prediction)\r\n",
        "  \r\n",
        "  predicted_label = np.argmax(prediction)\r\n",
        "  print(predicted_label)\r\n",
        "\r\n",
        "  predicted_label = labels[np.argmax(prediction)]\r\n",
        "  print(predicted_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.07308846 0.11211583 0.03174089 0.7830548 ]]\n",
            "3\n",
            "tech\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpRH3K72wh7i",
        "outputId": "fb2d6acd-f1d7-4fb0-e784-0d5c196eedfe"
      },
      "source": [
        "for i in range(10):\r\n",
        "  prediction = model.predict(np.array([x_test[i]]))\r\n",
        "  predicted_label = labels[np.argmax(prediction)]\r\n",
        "  print(prediction)\r\n",
        "  print(predicted_label)\r\n",
        "  print('Actual Label:',test_tag.iloc[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.3026340e-13 1.1022274e-13 2.8401281e-09 1.0000000e+00]]\n",
            "tech\n",
            "Actual Label: tech\n",
            "[[1.1319707e-07 9.9999928e-01 1.3012733e-07 5.2237465e-07]]\n",
            "entertainment\n",
            "Actual Label: entertainment\n",
            "[[5.0112541e-04 9.9837214e-01 2.8943649e-04 8.3729101e-04]]\n",
            "entertainment\n",
            "Actual Label: entertainment\n",
            "[[9.8025060e-01 1.1146893e-04 1.9548396e-02 8.9559777e-05]]\n",
            "business\n",
            "Actual Label: business\n",
            "[[9.9681002e-01 1.7046756e-03 1.2788232e-03 2.0635815e-04]]\n",
            "business\n",
            "Actual Label: business\n",
            "[[6.2400252e-11 4.7671903e-13 1.0000000e+00 7.0731610e-13]]\n",
            "politics\n",
            "Actual Label: politics\n",
            "[[7.8792922e-10 9.9999988e-01 6.3367288e-08 5.8553876e-08]]\n",
            "entertainment\n",
            "Actual Label: entertainment\n",
            "[[8.36081563e-06 1.38216834e-07 9.99991417e-01 1.05163856e-07]]\n",
            "politics\n",
            "Actual Label: politics\n",
            "[[9.2123926e-08 2.9234873e-02 9.7076076e-01 4.2655379e-06]]\n",
            "politics\n",
            "Actual Label: politics\n",
            "[[1.75066824e-15 5.21046229e-16 1.00000000e+00 1.12992035e-14]]\n",
            "politics\n",
            "Actual Label: politics\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry2F47tDE8qa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}